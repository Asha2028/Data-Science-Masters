{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb06f9d0",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c3f75",
   "metadata": {},
   "source": [
    "Ans:\n",
    "    \n",
    "Web scrapping ia an automatic method to obtain large amoiunts of data from websites. To extract the larger data from websites as quickly as possible, we use web scrapping. Web scraping uses intelligence automation methods to get thousands or even millions of data sets in a smaller amount of time. \n",
    "\n",
    "Web scraping requires two parts, namely the crawler and the scraper. The crawler is an artificial intelligence algorithm that browses the web to search for the particular data required by following the links across the internet. The scraper, on the other hand, is a specific tool created to extract data from the website. The design of the scraper can vary greatly according to the complexity and scope of the project so that it can quickly and accurately extract the data.\n",
    "\n",
    "Web Scraping has multiple applications across various industries. Let’s check out some of these now!\n",
    "\n",
    "1. Price Monitoring\n",
    "Web Scraping can be used by companies to scrap the product data for their products and competing products as well to see how it impacts their pricing strategies. Companies can use this data to fix the optimal pricing for their products so that they can obtain maximum revenue.\n",
    "\n",
    "2. Market Research\n",
    "Web scraping can be used for market research by companies. High-quality web scraped data obtained in large volumes can be very helpful for companies in analyzing consumer trends and understanding which direction the company should move in the future. \n",
    "\n",
    "3. News Monitoring\n",
    "Web scraping news sites can provide detailed reports on the current news to a company. This is even more essential for companies that are frequently in the news or that depend on daily news for their day-to-day functioning. After all, news reports can make or break a company in a single day! ans so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f48d584",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4434ec1a",
   "metadata": {},
   "source": [
    "Ans:\n",
    "    \n",
    "Web Scrapers can be divided on the basis of many different criteria, including Self-built or Pre-built Web Scrapers, Browser extension or Software Web Scrapers, and Cloud or Local Web Scrapers.\n",
    "\n",
    "You can have Self-built Web Scrapers but that requires advanced knowledge of programming. And if you want more features in your Web Scraper, then you need even more knowledge. On the other hand, pre-built Web Scrapers are previously created scrapers that you can download and run easily. These also have more advanced options that you can customize.\n",
    "\n",
    "Browser extensions Web Scrapers are extensions that can be added to your browser. These are easy to run as they are integrated with your browser, but at the same time, they are also limited because of this. Any advanced features that are outside the scope of your browser are impossible to run on Browser extension Web Scrapers. But Software Web Scrapers don’t have these limitations as they can be downloaded and installed on your computer. These are more complex than Browser web scrapers, but they also have advanced features that are not limited by the scope of your browser.\n",
    "\n",
    "Cloud Web Scrapers run on the cloud, which is an off-site server mostly provided by the company that you buy the scraper from. These allow your computer to focus on other tasks as the computer resources are not required to scrape data from websites. Local Web Scrapers, on the other hand, run on your computer using local resources. So, if the Web scrapers require more CPU or RAM, then your computer will become slow and not be able to perform other tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f399600e",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfc5167",
   "metadata": {},
   "source": [
    "Ans:\n",
    "    \n",
    "Beautiful Soup is another Python library that is highly suitable for Web Scraping. It creates a parse tree that can be used to extract data from HTML on a website. Beautiful soup also has multiple features for navigation, searching, and modifying these parse trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9039a",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6774ce74",
   "metadata": {},
   "source": [
    "Flask is used because of its light weight web framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4341051f",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5152820c",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "1. Code pipeline: With the help of codepipeline, we are able to connect the github to Elastic beanstalk. AWS CodePipeline is a continuous delivery service used to model, visualize, and automate the steps required to release the software\n",
    "2. Elastic Beanstalk: We use CodePipeline with Elastic Beanstalk for continuous delivery of web applications to the cloud Elastic Beanstalk is a compute service that lets you deploy web applications and services to web servers. We use CodePipeline with Elastic Beanstalk for continuous deployment of web applications to your application environment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d344d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
